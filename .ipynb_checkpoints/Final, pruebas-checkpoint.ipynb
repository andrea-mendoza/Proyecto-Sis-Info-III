{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter \n",
    "import re,string,unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I saw this movie yesterday and thought it was awful; it was pointless and just plain stupid. the supposed plot concerned a prospective bridegroom too caught up in the problems of the world to relate to his bride and the other people in his life. He disappears on his wedding day (in a tux no less) and hooks up with an assortment of weirdos.<br /><br />We saw it with a bus-load of people on the way down to Atlantic City and everyone agreed that it was a terrible movie. It was trying to be profound but it wasn't; it was stupid and offensive. If I wasn't on a bus I would have walked out on the movie. Anyone considering seeing the movie or renting or buying the video you have been forewarned.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_ds = pd.read_csv(os.path.join(\"imdb_dataset.csv\"),encoding = \"ISO-8859-1\")\n",
    "review_column = \"Review\"\n",
    "## encoding = \"ISO-8859-1\"\n",
    "# encoding = \"cp1252\"\n",
    "\n",
    "review = movies_ds[review_column].loc[50]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_html_string(text):\n",
    "    html_text = BeautifulSoup(text, \"html.parser\")\n",
    "    return html_text.get_text()\n",
    "review = to_html_string(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    clean_text = re.sub('\\[[^]]*\\]', ' ', text)\n",
    "    clean_text = review = re.sub('[^a-zA-Z]', ' ', clean_text)\n",
    "    return clean_text.lower()\n",
    "   \n",
    "review = text_cleaner(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    return text.split()\n",
    "\n",
    "review = split_text(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'saw',\n",
       " 'movie',\n",
       " 'yesterday',\n",
       " 'thought',\n",
       " 'awful',\n",
       " 'pointless',\n",
       " 'plain',\n",
       " 'stupid',\n",
       " 'supposed',\n",
       " 'plot',\n",
       " 'concerned',\n",
       " 'prospective',\n",
       " 'bridegroom',\n",
       " 'caught',\n",
       " 'problem',\n",
       " 'world',\n",
       " 'relate',\n",
       " 'bride',\n",
       " 'people',\n",
       " 'life',\n",
       " 'he',\n",
       " 'disappears',\n",
       " 'wedding',\n",
       " 'day',\n",
       " 'tux',\n",
       " 'le',\n",
       " 'hook',\n",
       " 'assortment',\n",
       " 'weirdo',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'bus',\n",
       " 'load',\n",
       " 'people',\n",
       " 'way',\n",
       " 'atlantic',\n",
       " 'city',\n",
       " 'everyone',\n",
       " 'agreed',\n",
       " 'terrible',\n",
       " 'movie',\n",
       " 'it',\n",
       " 'trying',\n",
       " 'profound',\n",
       " 'stupid',\n",
       " 'offensive',\n",
       " 'if',\n",
       " 'i',\n",
       " 'bus',\n",
       " 'i',\n",
       " 'would',\n",
       " 'walked',\n",
       " 'movie',\n",
       " 'anyone',\n",
       " 'considering',\n",
       " 'seeing',\n",
       " 'movie',\n",
       " 'renting',\n",
       " 'buying',\n",
       " 'video',\n",
       " 'forewarned']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lem = WordNetLemmatizer()\n",
    "review = [lem.lemmatize(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saw',\n",
       " 'movie',\n",
       " 'yesterday',\n",
       " 'thought',\n",
       " 'awful',\n",
       " 'pointless',\n",
       " 'plain',\n",
       " 'stupid',\n",
       " 'supposed',\n",
       " 'plot',\n",
       " 'concerned',\n",
       " 'prospective',\n",
       " 'bridegroom',\n",
       " 'caught',\n",
       " 'problems',\n",
       " 'world',\n",
       " 'relate',\n",
       " 'bride',\n",
       " 'people',\n",
       " 'life',\n",
       " 'disappears',\n",
       " 'wedding',\n",
       " 'day',\n",
       " 'tux',\n",
       " 'less',\n",
       " 'hooks',\n",
       " 'assortment',\n",
       " 'weirdos',\n",
       " 'saw',\n",
       " 'bus',\n",
       " 'load',\n",
       " 'people',\n",
       " 'way',\n",
       " 'atlantic',\n",
       " 'city',\n",
       " 'everyone',\n",
       " 'agreed',\n",
       " 'terrible',\n",
       " 'movie',\n",
       " 'trying',\n",
       " 'profound',\n",
       " 'stupid',\n",
       " 'offensive',\n",
       " 'bus',\n",
       " 'would',\n",
       " 'walked',\n",
       " 'movie',\n",
       " 'anyone',\n",
       " 'considering',\n",
       " 'seeing',\n",
       " 'movie',\n",
       " 'renting',\n",
       " 'buying',\n",
       " 'video',\n",
       " 'forewarned']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saw movie yesterday thought awful pointless plain stupid supposed plot concerned prospective bridegroom caught problem world relate bride people life disappears wedding day tux le hook assortment weirdo saw bus load people way atlantic city everyone agreed terrible movie trying profound stupid offensive bus would walked movie anyone considering seeing movie renting buying video forewarned'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stop_words = set( nltk.corpus.stopwords.words('english'))\n",
    "english_stop_words\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def to_html_string(text):\n",
    "    html_text = BeautifulSoup(text, \"html.parser\")\n",
    "    return html_text.get_text()\n",
    "\n",
    "def text_cleaner(text):\n",
    "    clean_text = re.sub('\\[[^]]*\\]', ' ', text)\n",
    "    clean_text = review = re.sub('[^a-zA-Z]', ' ', clean_text)\n",
    "    return clean_text.lower()\n",
    "\n",
    "def split_text(text):\n",
    "    return text.split()\n",
    "\n",
    "def normalize_document(text):\n",
    "    normalize_text = to_html_string(text)\n",
    "    normalize_text = text_cleaner(normalize_text)\n",
    "    normalize_text = split_text(normalize_text)\n",
    "    normalize_text = [word.lower() for word in normalize_text if not word in english_stop_words]\n",
    "    normalize_text = [lem.lemmatize(word) for word in normalize_text]\n",
    "    return  (' '.join(normalize_text))\n",
    "\n",
    "normalize_document(movies_ds[review_column].loc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i saw movie yesterday thought awful pointless plain stupid supposed plot concerned prospective bridegroom caught problem world relate bride people life he disappears wedding day tux le hook assortment weirdo we saw bus load people way atlantic city everyone agreed terrible movie it trying profound stupid offensive if i bus i would walked movie anyone considering seeing movie renting buying video forewarned'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movies_ds['Review']=movies_ds['Review'].apply(normalize_document)\n",
    "\n",
    "# movies_ds[review_column].loc[50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
