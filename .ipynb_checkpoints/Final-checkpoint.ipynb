{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter \n",
    "import re,string,unicodedata\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  Once again Mr. Costner has dragged out a movie...   neg\n",
       "1  This is an example of why the majority of acti...   neg\n",
       "2  First of all I hate those moronic rappers, who...   neg\n",
       "3  Not even the Beatles could write songs everyon...   neg\n",
       "4  Brass pictures (movies is not a fitting word f...   neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_ds = pd.read_csv(os.path.join(\"imdb_dataset.csv\"),encoding = \"ISO-8859-1\")\n",
    "## encoding = \"ISO-8859-1\"\n",
    "# encoding = \"cp1252\"\n",
    "\n",
    "movies_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de etiquetas <br /> html\n",
    "\n",
    "movies_ds['Review'] = movies_ds['Review'].str.replace('<br />', '')\n",
    "movies_ds['Review'] = movies_ds['Review'].str.replace(\"\\'\", \"'\")\n",
    "movies_ds['Review'] = movies_ds['Review'].str.replace('\"', '')\n",
    "\n",
    "\n",
    "english_stop_words = set( nltk.corpus.stopwords.words('english')+list(string.punctuation)+[\"can't\"])\n",
    "\n",
    "movies_ds['Review'].get(7)\n",
    "\n",
    "# english_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"being long-time fan japanese film i expected i ca n't really bothered write much movie poor the story might cutest romantic little something ever pity i could n't stand awful acting mess called pacing standard `` quirky '' japanese story if 've noticed many japanese movies use characters plots twists seem `` different '' forcedly steer clear movie seriously 12-year old could told movie going move along 's good thing book. br br fans `` beat '' takeshi part movie really cameo unless 're rabid fan n't need suffer waste film. br br 2/10\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = \"\"\"Being a long-time fan of Japanese film, I expected more than this. I can't really be bothered to write to much, as this movie is just so poor. The story might be the cutest romantic little something ever, pity I couldn't stand the awful acting, the mess they called pacing, and the standard \"quirky\" Japanese story. If you've noticed how many Japanese movies use characters, plots and twists that seem too \"different\", forcedly so, then steer clear of this movie. Seriously, a 12-year old could have told you how this movie was going to move along, and that's not a good thing in my book.Fans of \"Beat\" Takeshi: his part in this movie is not really more than a cameo, and unless you're a rabid fan, you don't need to suffer through this waste of film.2/10\"\"\"\n",
    "english_stop_words = set( nltk.corpus.stopwords.words('english')+list(string.punctuation)+[\"can't\"])\n",
    "\n",
    "def normalize_document(document, language='english'):\n",
    "    tokens = nltk.word_tokenize(document,language)\n",
    "    filtered_tokens = [token.lower() for token in tokens if token not in english_stop_words]\n",
    "    normalized_document = \" \".join(filtered_tokens);\n",
    "    return normalized_document\n",
    "\n",
    "# movies_ds['Review'].get(7)\n",
    "normalize_document(movies_ds['Review'].get(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "movies_ds['Review']=movies_ds['Review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "movies_ds['Review']=movies_ds['Review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longtim fan japanes film expect thi cant realli bother write much thi movi poor stori might cutest romant littl someth ever piti stand aw act mess call pace standard quirki japanes stori youv notic mani japanes movi use charact plot twist seem differ forcedli steer clear thi movi serious 12year old could told thi movi wa go move along good thing bookfan beat takeshi hi part thi movi realli cameo unless rabid fan need suffer thi wast film210'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=ToktokTokenizer()\n",
    "#set stopwords to english\n",
    "\n",
    "stop=set(nltk.corpus.stopwords.words('english'))\n",
    "stop=[word.replace(\"'\", '') for word in stop]\n",
    "# print(stop)\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stop]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "movies_ds['Review']=movies_ds['Review'].apply(remove_stopwords)\n",
    "\n",
    "movies_ds['Review'].get(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
