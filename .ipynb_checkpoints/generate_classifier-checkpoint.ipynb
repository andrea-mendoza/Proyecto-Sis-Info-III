{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from processing_text import get_clean_text ##archivo que nosotros hicimos :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ds = pd.read_csv(os.path.join(\"imdb_dataset.csv\"),encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(movies_ds['Review'], movies_ds['Label'], test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = (y_train.replace({'pos': 1, 'neg': 0})).values\n",
    "y_test  = (y_test.replace({'pos': 1, 'neg': 0})).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(documents):\n",
    "    return np.array([get_clean_text(document) for document in documents])\n",
    "\n",
    "normalized_corpus_train = normalize_corpus(X_train)\n",
    "normalized_corpus_test = normalize_corpus(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=10000,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(normalized_corpus_train)\n",
    "X = cv.transform(normalized_corpus_train)\n",
    "X_test = cv.transform(normalized_corpus_test)\n",
    "\n",
    "clasificador_reg_log = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "\n",
    "\n",
    "pipeline = make_pipeline(cv, clasificador_reg_log)\n",
    "pipeline.fit(normalized_corpus_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_clasificador = os.path.join(\"logistic_regression.pkl\")\n",
    "archivo_clasificador = open(ruta_archivo_clasificador, \"wb\")\n",
    "pickle.dump(pipeline, archivo_clasificador)\n",
    "archivo_clasificador.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy del clasificador regresion logistica - version 1 : 0.89\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "one_hot_accuracy = accuracy_score(y_test, pipeline.predict(normalized_corpus_test))\n",
    "print('Exactitud del clasificador regresion logistica - version 1 : {0:.2f}'.format(one_hot_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy del clasificador de random forest- version 1 : 0.86\n"
     ]
    }
   ],
   "source": [
    "tree_v3 = RandomForestClassifier(n_estimators=100)\n",
    "pipeline3 = make_pipeline(cv, tree_v3)\n",
    "\n",
    "pipeline3.fit(normalized_corpus_train,y_train)\n",
    "\n",
    "random_forest_accuracy = accuracy_score(y_test, pipeline3.predict(normalized_corpus_test))\n",
    "print('Exactitud del clasificador de random forest- version 1 : {0:.2f}'.format(random_forest_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy del clasificador de arbol de decision- version 1 : 0.73\n"
     ]
    }
   ],
   "source": [
    "tree_v2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=50)\n",
    "pipeline2 = make_pipeline(cv, tree_v2)\n",
    "\n",
    "pipeline2.fit(normalized_corpus_train,y_train) \n",
    "decision_tree_accuracy = accuracy_score(y_test, pipeline2.predict(normalized_corpus_test))\n",
    "\n",
    "print('Exactitud del clasificador de arbol de decision- version 1 : {0:.2f}'.format(decision_tree_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "tree_v4 = XGBClassifier(n_estimators=400,max_depth=6)\n",
    "\n",
    "pipeline4 = make_pipeline(cv, tree_v4)\n",
    "pipeline4.fit(normalized_corpus_train,y_train)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, pipeline4.predict(normalized_corpus_test))\n",
    "print('Exactitud del clasificador XGB - version 1 : {0:.2f}'.format(xgb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'lab':['Logistic Regression', 'Random Forest', 'Decision Tree', 'XGClassifier'], 'val':[one_hot_accuracy, random_forest_accuracy, decision_tree_accuracy, xgb_accuracy]})\n",
    "df.plot.bar(x='lab', y='val', rot=0, color=['r','b','g','y'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
